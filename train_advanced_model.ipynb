{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸŒ¿ FloraGuard AI - Professional Model Training\n",
    "\n",
    "This notebook trains a high-performance Plant Disease Detection model using **Transfer Learning** with **MobileNetV2**.\n",
    "\n",
    "### Why this is better:\n",
    "- **MobileNetV2**: A state-of-the-art architecture optimized for mobile/web speed and accuracy.\n",
    "- **Transfer Learning**: Uses knowledge from millions of images (ImageNet) to understand features better.\n",
    "- **Data Augmentation**: Simulates real-world conditions (rotation, lighting, zoom) to prevent overfitting.\n",
    "\n",
    "### Instructions:\n",
    "1.  Run all cells in order.\n",
    "2.  The notebook will download the dataset automatically.\n",
    "3.  It will train the model and save it as `model.tflite`.\n",
    "4.  Download `model.tflite` and `labels.txt` and use them in your Web App."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title 1. Setup & Install Dependencies\n",
    "!pip install -q tensorflow tensorflow-datasets matplotlib numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title 2. Download Dataset (PlantVillage)\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "print(\"Downloading PlantVillage dataset... This may take a few minutes.\")\n",
    "\n",
    "# Load PlantVillage dataset from TensorFlow Datasets\n",
    "# We use 'plant_village' which contains 38 classes\n",
    "(train_ds, val_ds, test_ds), metadata = tfds.load(\n",
    "    'plant_village',\n",
    "    split=['train[:80%]', 'train[80%:90%]', 'train[90%:]'],\n",
    "    with_info=True,\n",
    "    as_supervised=True,\n",
    ")\n",
    "\n",
    "num_classes = metadata.features['label'].num_classes\n",
    "class_names = metadata.features['label'].names\n",
    "\n",
    "print(f\"Dataset loaded successfully!\")\n",
    "print(f\"Total Classes: {num_classes}\")\n",
    "print(f\"Class Names: {class_names}\")\n",
    "\n",
    "# Save labels to file\n",
    "with open('labels.txt', 'w') as f:\n",
    "    for name in class_names:\n",
    "        f.write(name + '\\n')\n",
    "print(\"labels.txt saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title 3. Preprocessing & Data Augmentation\n",
    "IMG_SIZE = 224 # MobileNetV2 expects 224x224\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "resize_and_rescale = tf.keras.Sequential([\n",
    "  tf.keras.layers.Resizing(IMG_SIZE, IMG_SIZE),\n",
    "  tf.keras.layers.Rescaling(1./255)\n",
    "])\n",
    "\n",
    "data_augmentation = tf.keras.Sequential([\n",
    "  tf.keras.layers.RandomFlip(\"horizontal_and_vertical\"),\n",
    "  tf.keras.layers.RandomRotation(0.2),\n",
    "  tf.keras.layers.RandomZoom(0.2),\n",
    "  tf.keras.layers.RandomContrast(0.2),\n",
    "])\n",
    "\n",
    "def prepare(ds, shuffle=False, augment=False):\n",
    "  # Resize and Rescale all datasets\n",
    "  ds = ds.map(lambda x, y: (resize_and_rescale(x), y), \n",
    "              num_parallel_calls=tf.data.AUTOTUNE)\n",
    "\n",
    "  if shuffle:\n",
    "    ds = ds.shuffle(1000)\n",
    "\n",
    "  # Batch all datasets\n",
    "  ds = ds.batch(BATCH_SIZE)\n",
    "\n",
    "  # Use data augmentation only on the training set\n",
    "  if augment:\n",
    "    ds = ds.map(lambda x, y: (data_augmentation(x, training=True), y), \n",
    "                num_parallel_calls=tf.data.AUTOTUNE)\n",
    "\n",
    "  # Use buffered prefetching on all datasets\n",
    "  return ds.prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "\n",
    "train_ds = prepare(train_ds, shuffle=True, augment=True)\n",
    "val_ds = prepare(val_ds)\n",
    "test_ds = prepare(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title 4. Build Model (MobileNetV2)\n",
    "base_model = tf.keras.applications.MobileNetV2(\n",
    "    input_shape=(IMG_SIZE, IMG_SIZE, 3),\n",
    "    include_top=False,\n",
    "    weights='imagenet'\n",
    ")\n",
    "\n",
    "base_model.trainable = False # Freeze base model\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "  base_model,\n",
    "  tf.keras.layers.GlobalAveragePooling2D(),\n",
    "  tf.keras.layers.Dropout(0.2),\n",
    "  tf.keras.layers.Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "  optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n",
    "  loss='sparse_categorical_crossentropy',\n",
    "  metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title 5. Train Model\n",
    "epochs = 10 # Start with 10, increase if needed\n",
    "\n",
    "history = model.fit(\n",
    "  train_ds,\n",
    "  validation_data=val_ds,\n",
    "  epochs=epochs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title 6. Fine-Tuning (Optional but Recommended)\n",
    "print(\"Unfreezing base model layers for fine-tuning...\")\n",
    "base_model.trainable = True\n",
    "\n",
    "# Fine-tune from this layer onwards\n",
    "fine_tune_at = 100\n",
    "\n",
    "# Freeze all the layers before the `fine_tune_at` layer\n",
    "for layer in base_model.layers[:fine_tune_at]:\n",
    "  layer.trainable = False\n",
    "\n",
    "model.compile(\n",
    "  optimizer=tf.keras.optimizers.RMSprop(learning_rate=0.00001),  # Lower learning rate\n",
    "  loss='sparse_categorical_crossentropy',\n",
    "  metrics=['accuracy']\n",
    ")\n",
    "\n",
    "fine_tune_epochs = 5\n",
    "total_epochs =  epochs + fine_tune_epochs\n",
    "\n",
    "history_fine = model.fit(\n",
    "  train_ds,\n",
    "  validation_data=val_ds,\n",
    "  initial_epoch=history.epoch[-1],\n",
    "  epochs=total_epochs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title 7. Convert to TFLite\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "# Save the model\n",
    "with open('model.tflite', 'wb') as f:\n",
    "  f.write(tflite_model)\n",
    "\n",
    "print(\"Model converted and saved as 'model.tflite'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title 8. Download Files\n",
    "from google.colab import files\n",
    "files.download('model.tflite')\n",
    "files.download('labels.txt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
